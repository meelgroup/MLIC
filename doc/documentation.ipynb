{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learn Binary classification rules\n",
    "\n",
    "This tutorial shows how to learn classification rules using MaxSAT-based incremental learning framework, IMLI. We show how to learn five popular classification rules under the same framework. \n",
    "\n",
    "- CNF rules (Conjunctive Normal Form)\n",
    "- DNF rules (Disjunctive Normal Form)\n",
    "- Decision sets\n",
    "- Decision lists\n",
    "- relaxed-CNF rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pyrulelearn.imli import imli\n",
    "from pyrulelearn import utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration\n",
    "\n",
    "Our first objective is to learn a classification rule in <em>CNF</em>, where the decision rule is ANDs of ORs of input features. For that, we specify `rule_type = CNF` inside the classification model `imli`. In this example, we learn a 2 clause rule with following hyper-parameters.\n",
    "\n",
    "- `rule_type` sets the type of classification rule. Other possible options are DNF, decision sets, decision lists, relaxed_CNF,\n",
    "- `num_clause` decides the number of clauses in the classfication rule,\n",
    "- `data_fidelity` decides the weight on classification error during training,\n",
    "- `weight_feature` decides the weight of rule-complexity, that is, the cost of introducing a Boolean feature in the classifier rule,\n",
    "\n",
    "\n",
    "We require a MaxSAT solver to learn the Boolean rule. In this example, we use `open-wbo` as the MaxSAT solver. To install a MaxSAT solver, we refer to instructions in [README](../README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = imli(rule_type=\"CNF\", num_clause=2,  data_fidelity=10, weight_feature=1, timeout=100, solver=\"open-wbo\", work_dir=\".\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "In this example, we learn a decision rule on `Iris` dataset. While the original dataset is used for multiclass classification, we modify it for binary classification. Our objective is to learn a decision rule that separates `Iris Versicolour` from other two classes of Iris: `Iris Setosa` and `Iris Virginica`. \n",
    "\n",
    "Our framework requires the training set to be discretized. In the following, we apply entropy-based discretization on the dataset. Alternatively, one can discreize the dataset of our own and directly use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['sepal length <  5.45',\n",
       "  'sepal length = (5.45 - 7.05)',\n",
       "  'sepal length >=  7.05',\n",
       "  'sepal width <  2.95',\n",
       "  'sepal width >=  2.95',\n",
       "  'petal length <  2.45',\n",
       "  'petal length = (2.45 - 4.75)',\n",
       "  'petal length >=  4.75',\n",
       "  'petal width <  0.8',\n",
       "  'petal width = (0.8 - 1.75)',\n",
       "  'petal width >=  1.75'],\n",
       " array([[1., 0., 0., ..., 1., 0., 0.],\n",
       "        [1., 0., 0., ..., 1., 0., 0.],\n",
       "        [1., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 0., 1.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X, y, features = utils.discretize_orange(\"../benchmarks/iris_orange.csv\")\n",
    "features, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report performance of the learned rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training report: \n              precision    recall  f1-score   support\n\n           0       0.98      0.95      0.97        65\n           1       0.92      0.97      0.94        35\n\n    accuracy                           0.96       100\n   macro avg       0.95      0.96      0.96       100\nweighted avg       0.96      0.96      0.96       100\n\n\ntest report: \n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        35\n           1       0.94      1.00      0.97        15\n\n    accuracy                           0.98        50\n   macro avg       0.97      0.99      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n"
     ]
    }
   ],
   "source": [
    "print(\"training report: \")\n",
    "print(classification_report(y_train, model.predict(X_train), target_names=['0','1']))\n",
    "print()\n",
    "print(\"test report: \")\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['0','1']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the learned rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learned rule is: \n\nAn Iris flower is predicted as Iris Versicolor if\npetal width = (0.8 - 1.75) AND\nnot sepal length >=  7.05\n"
     ]
    }
   ],
   "source": [
    "rule = model.get_rule(features)\n",
    "print(\"Learned rule is: \\n\")\n",
    "print(\"An Iris flower is predicted as Iris Versicolor if\")\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learn decision rules as DNF\n",
    "\n",
    "To learn a decision rule as a DNF (ORs of ANDs of input features), we specify `rule_type=DNF` in the parameters of the model. In the following, we learn a 2 clause DNF decision rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training report: \n              precision    recall  f1-score   support\n\n           0       0.98      0.95      0.97        65\n           1       0.92      0.97      0.94        35\n\n    accuracy                           0.96       100\n   macro avg       0.95      0.96      0.96       100\nweighted avg       0.96      0.96      0.96       100\n\n\ntest report: \n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        35\n           1       0.94      1.00      0.97        15\n\n    accuracy                           0.98        50\n   macro avg       0.97      0.99      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n\nRule:->\npetal width = (0.8 - 1.75) AND not sepal length >=  7.05 OR\npetal length = (2.45 - 4.75)\n\nOriginal features:\n['sepal length <  5.45', 'sepal length = (5.45 - 7.05)', 'sepal length >=  7.05', 'sepal width <  2.95', 'sepal width >=  2.95', 'petal length <  2.45', 'petal length = (2.45 - 4.75)', 'petal length >=  4.75', 'petal width <  0.8', 'petal width = (0.8 - 1.75)', 'petal width >=  1.75']\n\nIn the learned rule, show original index in the feature list with phase (1: original, -1: complemented)\n[[(2, 1), (9, -1)], [(6, -1)]]\n"
     ]
    }
   ],
   "source": [
    "model = imli(rule_type=\"DNF\", num_clause=2,  data_fidelity=10, solver=\"open-wbo\", work_dir=\".\", verbose=False)\n",
    "model.fit(X_train,y_train)\n",
    "print(\"training report: \")\n",
    "print(classification_report(y_train, model.predict(X_train), target_names=['0','1']))\n",
    "print()\n",
    "print(\"test report: \")\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['0','1']))\n",
    "\n",
    "print(\"\\nRule:->\")\n",
    "print(model.get_rule(features))\n",
    "print(\"\\nOriginal features:\")\n",
    "print(features)\n",
    "print(\"\\nIn the learned rule, show original index in the feature list with phase (1: original, -1: complemented)\")\n",
    "print(model.get_selected_column_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Learn more expressible decision rules: Relaxed-CNF rules\n",
    "\n",
    "Our framework allows one to learn more expressible decision rules, which we call relaxed_CNF rules. This rule allows thresholds on satisfaction of clauses and literals and can learn more complex decision boundaries. See the [ECAI-2020](https://bishwamittra.github.io/publication/ecai_2020/paper.pdf) paper for more details. \n",
    "\n",
    "\n",
    "In our framework, set the parameter `rule_type=relaxed_CNF` to learn the rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training report: \n              precision    recall  f1-score   support\n\n           0       0.98      0.95      0.97        65\n           1       0.92      0.97      0.94        35\n\n    accuracy                           0.96       100\n   macro avg       0.95      0.96      0.96       100\nweighted avg       0.96      0.96      0.96       100\n\n\ntest report: \n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        35\n           1       0.94      1.00      0.97        15\n\n    accuracy                           0.98        50\n   macro avg       0.97      0.99      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n"
     ]
    }
   ],
   "source": [
    "model = imli(rule_type=\"relaxed_CNF\", num_clause=2,  data_fidelity=10, solver=\"cplex\", work_dir=\".\", verbose=False)\n",
    "model.fit(X_train,y_train)\n",
    "print(\"training report: \")\n",
    "print(classification_report(y_train, model.predict(X_train), target_names=['0','1']))\n",
    "print()\n",
    "print(\"test report: \")\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the decision rule\n",
    "\n",
    "In this example, we ask the framework to learn a 2 clause rule. During training, we learn the thresholds on clauses and literals while fitting the dataset. The learned rule operates in two levels. In the first level, a clause is satisfied if the literals in the clause satisfy the learned threshold on literals. In the second level, the formula is satisfied when the threshold on clauses is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learned rule is: \n\nAn Iris flower is predicted as Iris Versicolor if\n[ (  petal width = (0.8 - 1.75)   )>= 1  ] +\n[ (  not sepal length >=  7.05   )>= 1  ]  >= 2\n\nThrehosld on clause: 2\nThreshold on literals: (this is a list where entries denote threholds on literals on all clauses)\n[1, 1]\n"
     ]
    }
   ],
   "source": [
    "rule = model.get_rule(features)\n",
    "print(\"Learned rule is: \\n\")\n",
    "print(\"An Iris flower is predicted as Iris Versicolor if\")\n",
    "print(rule)\n",
    "print(\"\\nThrehosld on clause:\", model.get_threshold_clause())\n",
    "print(\"Threshold on literals: (this is a list where entries denote threholds on literals on all clauses)\")\n",
    "print(model.get_threshold_literal())"
   ]
  },
  {
   "source": [
    "# 4. Learn decision rules as decision sets and lists\n",
    "\n",
    "### Decision sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nRule:->\nIf not petal width = (0.8 - 1.75): class = 0\nIf petal width = (0.8 - 1.75) AND not sepal length >=  7.05: class = 1\nIf sepal length >=  7.05 AND petal width = (0.8 - 1.75): class = 0\nIf sepal length >=  7.05 AND petal width <  0.8: class = 0\nElse : class = 0\n\ntraining report: \n              precision    recall  f1-score   support\n\n           0       0.98      0.95      0.97        65\n           1       0.92      0.97      0.94        35\n\n    accuracy                           0.96       100\n   macro avg       0.95      0.96      0.96       100\nweighted avg       0.96      0.96      0.96       100\n\n\ntest report: \n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        35\n           1       0.94      1.00      0.97        15\n\n    accuracy                           0.98        50\n   macro avg       0.97      0.99      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n"
     ]
    }
   ],
   "source": [
    "model = imli(rule_type=\"decision sets\", num_clause=5,  data_fidelity=10, solver=\"open-wbo\", work_dir=\".\", verbose=False)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(\"\\nRule:->\")\n",
    "print(model.get_rule(features))\n",
    "\n",
    "\n",
    "print(\"\\ntraining report: \")\n",
    "print(classification_report(y_train, model.predict(X_train), target_names=['0','1']))\n",
    "print()\n",
    "print(\"test report: \")\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['0','1']))\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Decision lists"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nRule:->\nIf not petal width = (0.8 - 1.75): class = 0\nElse if not sepal length >=  7.05: class = 1\nElse: class = 0\n\ntraining report: \n              precision    recall  f1-score   support\n\n           0       0.98      0.95      0.97        65\n           1       0.92      0.97      0.94        35\n\n    accuracy                           0.96       100\n   macro avg       0.95      0.96      0.96       100\nweighted avg       0.96      0.96      0.96       100\n\n\ntest report: \n              precision    recall  f1-score   support\n\n           0       1.00      0.97      0.99        35\n           1       0.94      1.00      0.97        15\n\n    accuracy                           0.98        50\n   macro avg       0.97      0.99      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n"
     ]
    }
   ],
   "source": [
    "model = imli(rule_type=\"decision lists\", num_clause=5,  data_fidelity=10, solver=\"open-wbo\", work_dir=\".\", verbose=False)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(\"\\nRule:->\")\n",
    "print(model.get_rule(features))\n",
    "\n",
    "\n",
    "print(\"\\ntraining report: \")\n",
    "print(classification_report(y_train, model.predict(X_train), target_names=['0','1']))\n",
    "print()\n",
    "print(\"test report: \")\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['0','1']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}