{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learn Boolean decision rules\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rulelearning.imli import imli as imli\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration\n",
    "\n",
    "We now create an instance of `imli` object. First we learn a classification rule in CNF, that is, the decision rule is ANDs of ORs of input features. For that, we specify `rule_type=CNF` inside the model. In this example, we learn a 2 clause rule with parameter `data_fidelity=10`. `data_fidelity` parameter sets the priority between accuracy and rule-sparsity such that a higher value of `data_fidelity` results in a more accurate rule. We require a MaxSAT solver to learn the Boolean rule. In this example, we use `open-wbo` as the MaxSAT solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = imli(rule_type=\"CNF\", num_clause=2,  data_fidelity=10, solver=\"open-wbo\", work_dir=\"rulelearning/\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "In this example, we learn a decision rule on `Iris` flower dataset. While the original dataset is used for multiclass classification, we modify it for binary classification. Our objective is to learn a decision rule that separates `Iris Versicolour` from other two classes of Iris: `Iris Setosa` and `Iris Virginica`. \n",
    "\n",
    "Our framework requires the training set to be discretized. In the following, we apply entropy-based discretization on the dataset. We have also implemented quantile-based discretization (call `X, y, features = model.discretize(\"benchmarks/iris.csv\")`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Applying entropy based discretization using Orange library\n- file name:  benchmarks/iris_orange.csv\n- the number of discretized features: 22\n"
    }
   ],
   "source": [
    "X, y, features = model.discretize_orange(\"benchmarks/iris_orange.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nTraining started for batch:  1\n- number of soft clauses:  93\n- number of Boolean variables: 157\n- number of hard and soft clauses: 863\n\n\nBatch tarining complete\n- number of literals in the rule: 2\n- number of training errors:    3 out of 49\n\nTraining started for batch:  2\n- number of soft clauses:  95\n- number of Boolean variables: 161\n- number of hard and soft clauses: 890\n\n\nBatch tarining complete\n- number of literals in the rule: 4\n- number of training errors:    1 out of 51\n"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following function is used to access the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement(cnf_matrix):\n",
    "    # print(cnf_matrix)\n",
    "    TN, FP, FN, TP = cnf_matrix.ravel()\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP)\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return TPR, TNR, PPV, NPV, FPR, FNR, FDR, ACC*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report performance of the learned rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nPrediction through MaxSAT formulation\n- number of soft clauses:  188\n- number of Boolean variables: 274\n- number of hard and soft clauses: 1753\n\nPrediction through MaxSAT formulation\n- number of soft clauses:  138\n- number of Boolean variables: 164\n- number of hard and soft clauses: 973\n\ntraining    accuracy:  96.0\ntest        accuracy:  98.0\n"
    }
   ],
   "source": [
    "yhat_train = model.predict(X_train, y_train)\n",
    "_, _, _, _, _, _, _, train_acc = measurement(confusion_matrix(y_train, yhat_train))\n",
    "yhat_test = model.predict(X_test, y_test)\n",
    "_, _, _, _, _, _, _, test_acc = measurement(confusion_matrix(y_test, yhat_test))\n",
    "print(\"\\ntraining    accuracy: \", train_acc)\n",
    "print(\"test        accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the learned rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned rule is: \n( sepal length = (5.45 - 7.05) OR petal length = (2.45 - 4.75) ) AND \n( petal length = (2.45 - 4.75) OR petal width = (0.8 - 1.75))\n"
    }
   ],
   "source": [
    "rule = model.get_rule(features)\n",
    "print(\"Learned rule is: \")\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learn decision rules as DNF\n",
    "\n",
    "To learn a decision rule as a DNF (ORs of ANDs of input features), we specify `rule_type=DNF` in the parameters of the model. In the following, we learn a 2 clause DNF decision rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = imli(rule_type=\"DNF\", num_clause=2,  data_fidelity=10, solver=\"open-wbo\", work_dir=\"rulelearning/\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\ntraining    accuracy:  96.0\ntest        accuracy:  98.0\n\nLearned rule is: \n( sepal length >=  7.05 AND not_petal width = (0.8 - 1.75) ) OR \n( not_petal length = (2.45 - 4.75))\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X, y, features = model.discretize_orange(\"benchmarks/iris_orange.csv\")\n",
    "model.fit(X_train,y_train)\n",
    "yhat_train = model.predict(X_train, y_train)\n",
    "_, _, _, _, _, _, _, train_acc = measurement(confusion_matrix(y_train, yhat_train))\n",
    "yhat_test = model.predict(X_test, y_test)\n",
    "_, _, _, _, _, _, _, test_acc = measurement(confusion_matrix(y_test, yhat_test))\n",
    "print(\"\\ntraining    accuracy: \", train_acc)\n",
    "print(\"test        accuracy: \", test_acc)\n",
    "rule = model.get_rule(features)\n",
    "print(\"\\nLearned rule is: \")\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Learn more expressible decision rules\n",
    "\n",
    "Our framework allows one to learn more expressible decision rules, which we call relaxed_CNF rules. This rule allows thresholds on satisfaction of clauses and literals and can learn more complex decision boundaries. See the [ECAI-2020](https://bishwamittra.github.io/publication/ecai_2020/paper.pdf) paper for more details. \n",
    "\n",
    "\n",
    "In our framework, set the parameter `rule_type=relaxed_CNF` to learn the rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imli(rule_type=\"relaxed_CNF\", num_clause=2,  data_fidelity=10, solver=\"cplex\", work_dir=\"rulelearning/\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\ntraining    accuracy:  95.0\ntest        accuracy:  98.0\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X, y, features = model.discretize_orange(\"benchmarks/iris_orange.csv\")\n",
    "model.fit(X_train,y_train)\n",
    "yhat_train = model.predict(X_train, y_train)\n",
    "_, _, _, _, _, _, _, train_acc = measurement(confusion_matrix(y_train, yhat_train))\n",
    "yhat_test = model.predict(X_test, y_test)\n",
    "_, _, _, _, _, _, _, test_acc = measurement(confusion_matrix(y_test, yhat_test))\n",
    "print(\"\\ntraining    accuracy: \", train_acc)\n",
    "print(\"test        accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the decision rule\n",
    "\n",
    "In this example, we ask the framework to learn a 2 clause rule. During training, we learn the thresholds on clauses and literals while fitting the dataset. The learned rule operates in two levels. In the first level, a clause is satisfied if the literals in the clause satisfy the learned threshold on literals. In the second level, the formula is satisfied when the threshold on clauses is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Learned rule is: \n[ (  petal length = (2.45 - 4.75)  + petal width = (0.8 - 1.75)   )>= 1  ] +\n[ ( )>= 0  ]  >= 2\n\nThrehosld on clause: 2\nThreshold on literals: (this is a list where the entrie denotes threholds on literals on all clauses)\n[1, 0]\n"
    }
   ],
   "source": [
    "rule = model.get_rule(features)\n",
    "print(\"Learned rule is: \")\n",
    "print(rule)\n",
    "print(\"\\nThrehosld on clause:\", model.get_threshold_clause())\n",
    "print(\"Threshold on literals: (this is a list where the entrie denotes threholds on literals on all clauses)\")\n",
    "print(model.get_threshold_literal())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}